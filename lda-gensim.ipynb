{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/tsukasa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_sm')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('portuguese')  \n",
    "\n",
    "stop_words.extend(['ir', 'aqui', 'ter', 'todo', 'fazer', 'dizer', 'falar', 'estar', 'hoje', 'algum', 'outro', 'ser',\n",
    "                   'querer', 'qualquer', 'nado', 'porque', 'vir', 'partir', 'governar', 'deputar', 'parlamentar', 'sr',\n",
    "                   'presidente', 'vice', 'discursar', 'parecer', 'vez', 'dar', 'ex', 'sim', 'levar', 'quase', 'chance',\n",
    "                   'ano', 'além', 'sob', 'termo', 'sempre', 'nenhum', 'coisa', 'frase', 'diverso', 'olhar', 'exas',\n",
    "                   'aliás', 'ficar', 'tanto', 'saber', 'colocar', 'tão', 'dia', 'senhor', 'então', 'tipo', 'lado',\n",
    "                   'palavra', 'gente', 'apresentar', 'continuar', 'lá', 'nº', 'nome', 'exª', 'ali', 'câmara',\n",
    "                   'comissão'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(texts_list):\n",
    "    for text in texts_list:\n",
    "        yield (gensim.utils.simple_preprocess(str(text), deacc=False))\n",
    "\n",
    "\n",
    "def remove_stopwords(matrix):\n",
    "    return [[word for word in simple_preprocess(str(line)) if word not in stop_words] for line in matrix]\n",
    "\n",
    "\n",
    "def lemmatization(matrix):\n",
    "    matrix_out = []\n",
    "    for line in matrix:\n",
    "        doc = nlp(\" \".join(line))\n",
    "        matrix_out.append([word.lemma_ for word in doc])\n",
    "    return matrix_out\n",
    "\n",
    "\n",
    "def n_grams(matrix):\n",
    "    n_grams_model = gensim.models.Phrases(matrix, min_count=2, threshold=10)\n",
    "    matrix_out = gensim.models.phrases.Phraser(n_grams_model)\n",
    "    return [matrix_out[line] for line in matrix]\n",
    "\n",
    "\n",
    "def create_dictionary(matrix):\n",
    "    return Dictionary(matrix)\n",
    "\n",
    "\n",
    "def create_corpus(id2word, matrix):\n",
    "    return [id2word.doc2bow(line) for line in matrix]\n",
    "\n",
    "\n",
    "def show_keywords(dictionary, corpus):\n",
    "    return [[(dictionary[word], frequency) for word, frequency in document] for document in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abrir', 1),\n",
       " ('absolutamente', 1),\n",
       " ('acordar', 6),\n",
       " ('ainda', 2),\n",
       " ('andar', 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('database/Joice Hasselmann Plenario 2019.json', encoding=\"utf8\")\n",
    "database = df.discursos.values.tolist()\n",
    "\n",
    "data_processing = list(tokenization(database))\n",
    "\n",
    "data_processing = remove_stopwords(data_processing)\n",
    "\n",
    "data_processing = lemmatization(data_processing)\n",
    "\n",
    "data_processing = remove_stopwords(data_processing)\n",
    "\n",
    "data_processing = n_grams(data_processing)\n",
    "\n",
    "data_processing = n_grams(data_processing)\n",
    "\n",
    "data_processing = remove_stopwords(data_processing)\n",
    "\n",
    "dictionary = create_dictionary(data_processing) \n",
    "\n",
    "dictionary.filter_extremes(no_below=2)\n",
    "\n",
    "corpus = create_corpus(dictionary, data_processing)\n",
    "\n",
    "keywords = show_keywords(dictionary, corpus)\n",
    "\n",
    "keywords[0][:5] # Show 5 words and frequency of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('previdência', 0.05273116),\n",
       "   ('pobre', 0.03654498),\n",
       "   ('novo', 0.035415255),\n",
       "   ('chegar', 0.023218049),\n",
       "   ('texto', 0.021028133),\n",
       "   ('contar', 0.02099908),\n",
       "   ('receber', 0.019363593),\n",
       "   ('haver', 0.015624786),\n",
       "   ('pagar', 0.013982807),\n",
       "   ('fato', 0.013751401)]),\n",
       " (1,\n",
       "  [('jovem', 0.03749265),\n",
       "   ('criança', 0.035909295),\n",
       "   ('oportunidade', 0.018858256),\n",
       "   ('menino', 0.018857466),\n",
       "   ('errar', 0.018857466),\n",
       "   ('prazo', 0.016572405),\n",
       "   ('cumprir', 0.015104181),\n",
       "   ('joice', 0.015074832),\n",
       "   ('trabalhar', 0.01466136),\n",
       "   ('único', 0.013966279)]),\n",
       " (2,\n",
       "  [('pedir', 0.038542446),\n",
       "   ('oposição', 0.027283832),\n",
       "   ('acordar', 0.025710754),\n",
       "   ('líder', 0.02259771),\n",
       "   ('importante', 0.02137309),\n",
       "   ('pautar', 0.020666208),\n",
       "   ('discussão', 0.020285219),\n",
       "   ('caminhar', 0.016633602),\n",
       "   ('pagar', 0.015073292),\n",
       "   ('pavimentar', 0.014475642)]),\n",
       " (3,\n",
       "  [('quebrar', 0.046635587),\n",
       "   ('previdência', 0.016254699),\n",
       "   ('melhor', 0.016033946),\n",
       "   ('idear', 0.015991375),\n",
       "   ('jogar', 0.015865743),\n",
       "   ('texto', 0.015728768),\n",
       "   ('informação', 0.015553131),\n",
       "   ('verdade', 0.00985046),\n",
       "   ('rombo', 0.008736304),\n",
       "   ('caber', 0.008735951)]),\n",
       " (4,\n",
       "  [('educação', 0.06971011),\n",
       "   ('brasil', 0.03398796),\n",
       "   ('entender', 0.02963651),\n",
       "   ('ministrar', 0.022310961),\n",
       "   ('vezar', 0.02074008),\n",
       "   ('precisar', 0.019842597),\n",
       "   ('dinheiro', 0.016248628),\n",
       "   ('acontecer', 0.015031118),\n",
       "   ('técnico', 0.014927085),\n",
       "   ('processar', 0.0149257975)])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=5, passes=200,\n",
    "                                            random_state=100, chunksize=5)\n",
    "\n",
    "lda_model.show_topics(num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
